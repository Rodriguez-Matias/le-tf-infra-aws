{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 This is the documentation for the Leverage Reference Architecture . It is built around the AWS Well Architected Framework , using a Terraform , Ansible and Helm . An its compose of the following 3 main repos: le-tf-infra-aws le-ansible-infra le-helm-infra Overview \u00b6 This repository contains all Terraform configuration files used to create Binbash Leverage Reference AWS Cloud Solutions Architecture. Getting Started \u00b6 See How it works for a whirlwind tour that will get you started. See User guide for a hands on help.","title":"Welcome"},{"location":"#welcome","text":"This is the documentation for the Leverage Reference Architecture . It is built around the AWS Well Architected Framework , using a Terraform , Ansible and Helm . An its compose of the following 3 main repos: le-tf-infra-aws le-ansible-infra le-helm-infra","title":"Welcome"},{"location":"#overview","text":"This repository contains all Terraform configuration files used to create Binbash Leverage Reference AWS Cloud Solutions Architecture.","title":"Overview"},{"location":"#getting-started","text":"See How it works for a whirlwind tour that will get you started. See User guide for a hands on help.","title":"Getting Started"},{"location":"development/","text":"Developing for Binbash Leverage \u00b6 This document explains how to get started with developing for Leverage Reference Architecture . It includes how to build, test, and release new versions. Quick Start \u00b6 Getting the code \u00b6 The code must be checked out from this same github.com repo inside the Binbash Leverage Github Organization . git clone git@github.com:binbashar/le-tf-infra-aws.git cd le-tf-infra-aws cd .. git clone git@github.com:binbashar/le-ansible-infra.git cd le-ansible-infra cd .. git clone git@github.com:binbashar/le-helm-infra cd le-helm-infra cd .. Initial developer environment build \u00b6 TODO Dependencies \u00b6 This guide requires you to install X v0.1 or newer. Deploying \u00b6 To deploy the Leverage Reference Architecture onto AWS. Please check the deployment guide Testing \u00b6 To run tests, just run... Releasing \u00b6 CircleCi PR auto-release job \u00b6 https://circleci.com/gh/binbashar/bb-devops-tf-infra-aws NOTE: Will only run after merged PR.","title":"Development"},{"location":"development/#developing-for-binbash-leverage","text":"This document explains how to get started with developing for Leverage Reference Architecture . It includes how to build, test, and release new versions.","title":"Developing for Binbash Leverage"},{"location":"development/#quick-start","text":"","title":"Quick Start"},{"location":"development/#getting-the-code","text":"The code must be checked out from this same github.com repo inside the Binbash Leverage Github Organization . git clone git@github.com:binbashar/le-tf-infra-aws.git cd le-tf-infra-aws cd .. git clone git@github.com:binbashar/le-ansible-infra.git cd le-ansible-infra cd .. git clone git@github.com:binbashar/le-helm-infra cd le-helm-infra cd ..","title":"Getting the code"},{"location":"development/#initial-developer-environment-build","text":"TODO","title":"Initial developer environment build"},{"location":"development/#dependencies","text":"This guide requires you to install X v0.1 or newer.","title":"Dependencies"},{"location":"development/#deploying","text":"To deploy the Leverage Reference Architecture onto AWS. Please check the deployment guide","title":"Deploying"},{"location":"development/#testing","text":"To run tests, just run...","title":"Testing"},{"location":"development/#releasing","text":"","title":"Releasing"},{"location":"development/#circleci-pr-auto-release-job","text":"https://circleci.com/gh/binbashar/bb-devops-tf-infra-aws NOTE: Will only run after merged PR.","title":"CircleCi PR auto-release job"},{"location":"support/","text":"Support \u00b6 Leverage Reference Architecture \u00b6 Please create a Github Issue to get immediate support from the Binbash Leverage Team Our Engineering & Support Team \u00b6 AWS Well Architected Review \u00b6 Feel free to contact us for an AWS Well Architected Framework Review Well Architected Framework Review Reference Study Case Operational Excellence Security Cost Optimization Reliability Performance Efficiency WAF Exta Material DevSecOps Security Audit - v0.1 WAF Cost Optimization Checklist - v0.1 Read More \u00b6 How AWS Well-Architected Reviews Can Drive a Customer-First Culture","title":"Support"},{"location":"support/#support","text":"","title":"Support"},{"location":"support/#leverage-reference-architecture","text":"Please create a Github Issue to get immediate support from the Binbash Leverage Team","title":"Leverage Reference Architecture"},{"location":"support/#our-engineering-support-team","text":"","title":"Our Engineering &amp; Support Team"},{"location":"support/#aws-well-architected-review","text":"Feel free to contact us for an AWS Well Architected Framework Review Well Architected Framework Review Reference Study Case Operational Excellence Security Cost Optimization Reliability Performance Efficiency WAF Exta Material DevSecOps Security Audit - v0.1 WAF Cost Optimization Checklist - v0.1","title":"AWS Well Architected Review"},{"location":"support/#read-more","text":"How AWS Well-Architected Reviews Can Drive a Customer-First Culture","title":"Read More"},{"location":"examples/","text":"Reference Architecture examples \u00b6 This directory contains a catalog of examples on how to run, configure and scale Leverage Reference Architecture. Please review the prerequisites before trying them. Category Name Description Complexity Level Organizations AWS Organization Orchestrate your Ref Architecture Multi-Account AWS Organization Intermediate K8s K8s Kops Setup a production scale K8s clusters via Terraform + Kops Advanced","title":"Introduction"},{"location":"examples/#reference-architecture-examples","text":"This directory contains a catalog of examples on how to run, configure and scale Leverage Reference Architecture. Please review the prerequisites before trying them. Category Name Description Complexity Level Organizations AWS Organization Orchestrate your Ref Architecture Multi-Account AWS Organization Intermediate K8s K8s Kops Setup a production scale K8s clusters via Terraform + Kops Advanced","title":"Reference Architecture examples"},{"location":"examples/PREREQUISITES/","text":"Prerequisites \u00b6 Many of the examples in this directory have common prerequisites .","title":"Prerequisites"},{"location":"examples/PREREQUISITES/#prerequisites","text":"Many of the examples in this directory have common prerequisites .","title":"Prerequisites"},{"location":"examples/k8s-kops/","text":"TODO: Add ref links here \u00b6","title":"K8s Kops"},{"location":"examples/k8s-kops/#todo-add-ref-links-here","text":"","title":"TODO: Add ref links here"},{"location":"examples/organization/","text":"TODO: Add ref links here \u00b6","title":"Organization"},{"location":"examples/organization/#todo-add-ref-links-here","text":"","title":"TODO: Add ref links here"},{"location":"how-it-works/","text":"How it works \u00b6 The objective of this document is to explain how the Binbash Leverage Reference AWS Cloud Solutions Architecture works, in particular how the Reference Architecure model is built and why we need it. Overview \u00b6 This repository contains all Terraform configuration files used to create Binbash Leverage Reference AWS Cloud Solutions Architecture that will be implemented on the Projects\u2019s AWS infrastructure. Info This documentation will provide a detailed reference of the tools and techs used, the needs they address and how they fit with the multiple practices we will be implementing. Ref Architecture \u00b6 Reference AWS Cloud Solutions architecture designed under optimal configs for the most popular modern web and mobile applications needs based on AWS \u201cWell Architected Framework\u201d. With it's complete Leverage DevOps Automation Code Library to rapidly implement it will solve your entire infrastructure and will grant you complete control of the source code and of course you'll be able to run it without us. Characteristics Faster updates (new features and bug fixes). Better code quality and modules maturity (proven and tested). Supported by Binbash, and Open ones even by Binbash + 1000\u2019s of top talented Open Source community contributors. Development cost savings. Client keeps full rights to all commercial, modification, distribution, and private use of the code (No Lock-In) through forks inside their own Projects repos (open-source and commercially reusable via license MIT and Apache 2.0 - https://choosealicense.com/licenses/). Documented. Reusable, Supported & Customizable. Reference Architecture Design \u00b6 DevOps Workflow model \u00b6 Important Considerations \u00b6 Assumptions AWS Regions: Multi Region setup \u2192 1ry: us-east-1 (N. Virginia) & 2ry: us-west-2 (Oregon). DevOps necessary repositories will be created. There will be feature branches ( ID-XXX -> master ) and either Binbash or the Client Engineers will be reviewers of each other and approvers (at least 1 approver). After deployment via IaC (Terraform, Ansible & Helm) all subsequent changes will be performed via versioned controlled code, by modifying the corresponding repository and running the proper IaC Automation execution. Will start the process via Local Workstations. Afterwards full exec automation will be considered via: Jenkins, CircleCI or Terraform Cloud Jobs (GitOps). Consideration: Note that any change manually performed will generate inconsistencies on the deployed resources (which left them out of governance and support scope). All AWS resources will be deployed via Terraform and rarely occasional CloudFormation, Python SDK & AWS CLI when the resource is not defined by Terraform (almost none scenario). All code and scripts will be included in the repository. Provisioning via Ansible for resources that need to be provisioned on an OS. Orchestration via Helm + Helmsfile for resources that need to be provisioned in Kubernetes (with Docker as preferred container engine). Infra as code deployments should run from the new ID-XXX or master branch. ID-XXX branch must be merged immediately (ASAP) via PR to the master branch. Consideration: validating that the changes within the code will only affect the desired target resources is the responsibility of the executor (to ensure everything is OK please consider exec after review/approved PR). All resources will be deployed in several new AWS accounts created inside the Client AWS Organization. Except for the AWS Legacy Account invitation to the AWS Org and OrganizationAccountAccessRole creation in it, there will be no intervention whatsoever in current Client Legacy Production account, unless required by Client authority and given a specific requirement. Info We will explore the details of all the relevant Client application stacks, CI/CD processes, monitoring, security, target service level objective (SLO) and others in a separate document.","title":"How it works"},{"location":"how-it-works/#how-it-works","text":"The objective of this document is to explain how the Binbash Leverage Reference AWS Cloud Solutions Architecture works, in particular how the Reference Architecure model is built and why we need it.","title":"How it works"},{"location":"how-it-works/#overview","text":"This repository contains all Terraform configuration files used to create Binbash Leverage Reference AWS Cloud Solutions Architecture that will be implemented on the Projects\u2019s AWS infrastructure. Info This documentation will provide a detailed reference of the tools and techs used, the needs they address and how they fit with the multiple practices we will be implementing.","title":"Overview"},{"location":"how-it-works/#ref-architecture","text":"Reference AWS Cloud Solutions architecture designed under optimal configs for the most popular modern web and mobile applications needs based on AWS \u201cWell Architected Framework\u201d. With it's complete Leverage DevOps Automation Code Library to rapidly implement it will solve your entire infrastructure and will grant you complete control of the source code and of course you'll be able to run it without us. Characteristics Faster updates (new features and bug fixes). Better code quality and modules maturity (proven and tested). Supported by Binbash, and Open ones even by Binbash + 1000\u2019s of top talented Open Source community contributors. Development cost savings. Client keeps full rights to all commercial, modification, distribution, and private use of the code (No Lock-In) through forks inside their own Projects repos (open-source and commercially reusable via license MIT and Apache 2.0 - https://choosealicense.com/licenses/). Documented. Reusable, Supported & Customizable.","title":"Ref Architecture"},{"location":"how-it-works/#reference-architecture-design","text":"","title":"Reference Architecture Design"},{"location":"how-it-works/#devops-workflow-model","text":"","title":"DevOps Workflow model"},{"location":"how-it-works/#important-considerations","text":"Assumptions AWS Regions: Multi Region setup \u2192 1ry: us-east-1 (N. Virginia) & 2ry: us-west-2 (Oregon). DevOps necessary repositories will be created. There will be feature branches ( ID-XXX -> master ) and either Binbash or the Client Engineers will be reviewers of each other and approvers (at least 1 approver). After deployment via IaC (Terraform, Ansible & Helm) all subsequent changes will be performed via versioned controlled code, by modifying the corresponding repository and running the proper IaC Automation execution. Will start the process via Local Workstations. Afterwards full exec automation will be considered via: Jenkins, CircleCI or Terraform Cloud Jobs (GitOps). Consideration: Note that any change manually performed will generate inconsistencies on the deployed resources (which left them out of governance and support scope). All AWS resources will be deployed via Terraform and rarely occasional CloudFormation, Python SDK & AWS CLI when the resource is not defined by Terraform (almost none scenario). All code and scripts will be included in the repository. Provisioning via Ansible for resources that need to be provisioned on an OS. Orchestration via Helm + Helmsfile for resources that need to be provisioned in Kubernetes (with Docker as preferred container engine). Infra as code deployments should run from the new ID-XXX or master branch. ID-XXX branch must be merged immediately (ASAP) via PR to the master branch. Consideration: validating that the changes within the code will only affect the desired target resources is the responsibility of the executor (to ensure everything is OK please consider exec after review/approved PR). All resources will be deployed in several new AWS accounts created inside the Client AWS Organization. Except for the AWS Legacy Account invitation to the AWS Org and OrganizationAccountAccessRole creation in it, there will be no intervention whatsoever in current Client Legacy Production account, unless required by Client authority and given a specific requirement. Info We will explore the details of all the relevant Client application stacks, CI/CD processes, monitoring, security, target service level objective (SLO) and others in a separate document.","title":"Important Considerations"},{"location":"how-it-works/read-more/","text":"Read more \u00b6 Make sure you check out the documentation in the docs directory. Moreover, consider some official AWS docs, blog post and whitepapers we've considered for the current Reference Solutions Architecture desing: CloudTrail for AWS Organizations: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html Reserved Instances - Multi Account: https://aws.amazon.com/about-aws/whats-new/2019/07/amazon-ec2-on-demand-capacity-reservations-shared-across-multiple-aws-accounts/ AWS Multiple Account Security Strategy: https://d0.awsstatic.com/aws-answers/AWS_Multi_Account_Security_Strategy.pdf AWS Multiple Account Billing Strategy: https://aws.amazon.com/answers/account-management/aws-multi-account-billing-strategy/ AWS Secure Account Setup: https://aws.amazon.com/answers/security/aws-secure-account-setup/ Authentication and Access Control for AWS Organizations: https://docs.aws.amazon.com/organizations/latest/userguide/orgs_permissions.html AWS Regions: https://www.concurrencylabs.com/blog/choose-your-aws-region-wisely/ VPC Peering: https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html Route53 DNS VPC Associations: https://aws.amazon.com/premiumsupport/knowledge-center/private-hosted-zone-different-account/ AWS Well Architected Framework: https://aws.amazon.com/blogs/apn/the-5-pillars-of-the-aws-well-architected-framework/ AWS Tagging strategies: https://aws.amazon.com/answers/account-management/aws-tagging-strategies/ Inviting an AWS Account to Join Your Organization : https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_invites.html","title":"Read More"},{"location":"how-it-works/read-more/#read-more","text":"Make sure you check out the documentation in the docs directory. Moreover, consider some official AWS docs, blog post and whitepapers we've considered for the current Reference Solutions Architecture desing: CloudTrail for AWS Organizations: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/creating-trail-organization.html Reserved Instances - Multi Account: https://aws.amazon.com/about-aws/whats-new/2019/07/amazon-ec2-on-demand-capacity-reservations-shared-across-multiple-aws-accounts/ AWS Multiple Account Security Strategy: https://d0.awsstatic.com/aws-answers/AWS_Multi_Account_Security_Strategy.pdf AWS Multiple Account Billing Strategy: https://aws.amazon.com/answers/account-management/aws-multi-account-billing-strategy/ AWS Secure Account Setup: https://aws.amazon.com/answers/security/aws-secure-account-setup/ Authentication and Access Control for AWS Organizations: https://docs.aws.amazon.com/organizations/latest/userguide/orgs_permissions.html AWS Regions: https://www.concurrencylabs.com/blog/choose-your-aws-region-wisely/ VPC Peering: https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html Route53 DNS VPC Associations: https://aws.amazon.com/premiumsupport/knowledge-center/private-hosted-zone-different-account/ AWS Well Architected Framework: https://aws.amazon.com/blogs/apn/the-5-pillars-of-the-aws-well-architected-framework/ AWS Tagging strategies: https://aws.amazon.com/answers/account-management/aws-tagging-strategies/ Inviting an AWS Account to Join Your Organization : https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_invites.html","title":"Read more"},{"location":"how-it-works/cdn/cdn/","text":"","title":"CDN"},{"location":"how-it-works/ci-cd/ci-cd/","text":"","title":"CI/CD"},{"location":"how-it-works/code-library/code-library-specs/","text":"Tech Specifications \u00b6 As Code: Hundred of thousands lines of code written in Terraform, Groovy (Jenkinsfiles), Ansible, Makefiles + Bash Dockerfiles Helm Charts \"Stop reinventing the wheel, automated and fully as code automated (executable from a single source). as code. parameterized variables input parameters return / output parameters \"stop reinventing the wheel\" avoid re-building the same things more than X times. avoid wasting time. not healthy, not secure and slows us down. DoD of a highly reusable, configurable, and composible sub-modules which will be 100% modular equivalent to other programming languages functions - Example for terraform - https://www.terraform.io/docs/modules/usage.html (but can be propagated for other languages and tools): inputs, outputs parameters. code reuse (reusable): consider tf modules and sub-modules approach. testable by module / function. Since TF it's oriented to work through 3rd party API calls, then tests are more likely to be integration tests rather than unit tests . If we don't allow integration for terraform then we can't work at all. This has to be analyzed for every language we'll be using and how we implement it (terraform, cloudformation, ansible, python, bash, docker, kops and k8s kubeclt cmds) composition (composible): have multiple functions and use it together eg: def_add(x,y){return x+y} ; def_sub(x,y){return x-y}; sub(add(3,4), add(7,5)) abstraction (abstract away complexity): we have a very complex function but we only expose it's definition to the API, eg: def_ai_processing(data_set){very complex algorithm here}; ai_processing([our_data_set_here]) Avoid inline: blocks The configuration for some Terraform resources can be defined either as inline blocks or as separate resources. When creating a module, you should always use a separate resource. For example, the aws_route_table resource allows you to define routes via inline blocks. Otherwise, your module will be less flexible and configurable. So If you try to use a mix of both inline blocks and separate resources, you run into bugs where they will conflict and overwrite each other. Therefore, you must use one or the other (ref: https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d )) Use module-relative paths: The catch is that the file path you use has to be relative (since you could run Terraform on many different computers)\u200a\u2014\u200abut what is it relative to? By default, Terraform interprets the path relative to the working directory. That\u2019s a good default for normal Terraform templates, but it won\u2019t work if the file is part of a module. To solve this issue, always use a path variable in file paths. eg: resource \"aws_instance\" \"example\" { ami = \"ami-2d39803a\" instance_type = \"t2.micro\" user_data = \"${file(\"${path.module}/user-data.sh\")}\" } Solutions must be versioned: So as to be able to manage them as a software product with releases and change log. In this way we'll be able to know which version is currently deployed in a certain client and consider it's upgrade. Env Parity Promote inmutable, versioned infra modules based across envs. Updated: Continually make updates, additions, and fixes to the libraries and modules. Integrated \"push button environments (PBE)\" approach for our solutions. - TODO: FLOW DIAGRAM HERE Proven & Tested: Customers & every commit goes through a suite of automated tests to gran code styling and functional testing. Develop a wrapper/jobs together with specific testing tools in order to grant the modules are working as expected. Ansible: https://www.jeffgeerling.com/blog/2018/testing-your-ansible-roles-molecule https://www.digitalocean.com/community/tutorials/how-to-test-ansible-roles-with-molecule-on-ubuntu-16-04 Terraform: gruntwork-io/terratest Cost savings: The architecture for our Library / Code Modules helps an organization to analyze its current IT and DevSecOps Cloud strategy and identify areas where changes could lead to cost savings. For instance, the architecture may show that multiple database systems could be changed so only one product is used, reducing software and support costs. Provides a basis for reuse.The process of architecting can support both the use and creation of reusable assets. Reusable assets are beneficial to an organization, since they can reduce the overall cost of a system and also improve its quality, given that a reusable asset has already been proven. Full Code Access & No Lock-In You get access to 100% of the code under Open Source license ( https://choosealicense.com/ ) so If you ever choose to cancel, you keep rights to all the code. Documented: Includes example code, use case and thorough documentation, such as README.md , --help command, doc-string and in line comments. Supported & Customizable: Commercially maintained and supported by Binbash .","title":"Specifications"},{"location":"how-it-works/code-library/code-library-specs/#tech-specifications","text":"As Code: Hundred of thousands lines of code written in Terraform, Groovy (Jenkinsfiles), Ansible, Makefiles + Bash Dockerfiles Helm Charts \"Stop reinventing the wheel, automated and fully as code automated (executable from a single source). as code. parameterized variables input parameters return / output parameters \"stop reinventing the wheel\" avoid re-building the same things more than X times. avoid wasting time. not healthy, not secure and slows us down. DoD of a highly reusable, configurable, and composible sub-modules which will be 100% modular equivalent to other programming languages functions - Example for terraform - https://www.terraform.io/docs/modules/usage.html (but can be propagated for other languages and tools): inputs, outputs parameters. code reuse (reusable): consider tf modules and sub-modules approach. testable by module / function. Since TF it's oriented to work through 3rd party API calls, then tests are more likely to be integration tests rather than unit tests . If we don't allow integration for terraform then we can't work at all. This has to be analyzed for every language we'll be using and how we implement it (terraform, cloudformation, ansible, python, bash, docker, kops and k8s kubeclt cmds) composition (composible): have multiple functions and use it together eg: def_add(x,y){return x+y} ; def_sub(x,y){return x-y}; sub(add(3,4), add(7,5)) abstraction (abstract away complexity): we have a very complex function but we only expose it's definition to the API, eg: def_ai_processing(data_set){very complex algorithm here}; ai_processing([our_data_set_here]) Avoid inline: blocks The configuration for some Terraform resources can be defined either as inline blocks or as separate resources. When creating a module, you should always use a separate resource. For example, the aws_route_table resource allows you to define routes via inline blocks. Otherwise, your module will be less flexible and configurable. So If you try to use a mix of both inline blocks and separate resources, you run into bugs where they will conflict and overwrite each other. Therefore, you must use one or the other (ref: https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d )) Use module-relative paths: The catch is that the file path you use has to be relative (since you could run Terraform on many different computers)\u200a\u2014\u200abut what is it relative to? By default, Terraform interprets the path relative to the working directory. That\u2019s a good default for normal Terraform templates, but it won\u2019t work if the file is part of a module. To solve this issue, always use a path variable in file paths. eg: resource \"aws_instance\" \"example\" { ami = \"ami-2d39803a\" instance_type = \"t2.micro\" user_data = \"${file(\"${path.module}/user-data.sh\")}\" } Solutions must be versioned: So as to be able to manage them as a software product with releases and change log. In this way we'll be able to know which version is currently deployed in a certain client and consider it's upgrade. Env Parity Promote inmutable, versioned infra modules based across envs. Updated: Continually make updates, additions, and fixes to the libraries and modules. Integrated \"push button environments (PBE)\" approach for our solutions. - TODO: FLOW DIAGRAM HERE Proven & Tested: Customers & every commit goes through a suite of automated tests to gran code styling and functional testing. Develop a wrapper/jobs together with specific testing tools in order to grant the modules are working as expected. Ansible: https://www.jeffgeerling.com/blog/2018/testing-your-ansible-roles-molecule https://www.digitalocean.com/community/tutorials/how-to-test-ansible-roles-with-molecule-on-ubuntu-16-04 Terraform: gruntwork-io/terratest Cost savings: The architecture for our Library / Code Modules helps an organization to analyze its current IT and DevSecOps Cloud strategy and identify areas where changes could lead to cost savings. For instance, the architecture may show that multiple database systems could be changed so only one product is used, reducing software and support costs. Provides a basis for reuse.The process of architecting can support both the use and creation of reusable assets. Reusable assets are beneficial to an organization, since they can reduce the overall cost of a system and also improve its quality, given that a reusable asset has already been proven. Full Code Access & No Lock-In You get access to 100% of the code under Open Source license ( https://choosealicense.com/ ) so If you ever choose to cancel, you keep rights to all the code. Documented: Includes example code, use case and thorough documentation, such as README.md , --help command, doc-string and in line comments. Supported & Customizable: Commercially maintained and supported by Binbash .","title":"Tech Specifications"},{"location":"how-it-works/code-library/code-library/","text":"Leverage DevOps Automation Code Library \u00b6 Overview \u00b6 A collection of reusable, tested, production-ready E2E infrastructure as code solutions, leveraged by modules written in Terraform, Ansible, Jenkinsfiles, Dockerfiles, Helm charts and Makefiles). Model \u00b6 Our development model is strongly based on code reusability Reusability \u00b6 High level summary of the the code reusability efficiency Considerations Above detailed % are to be seen as estimates AWS PCI-DSS Reference article AWS HIPAA Reference article AWS GDPR Reference article Modules \u00b6 DevOps Automation Code Library development and implementation workflow","title":"Overview"},{"location":"how-it-works/code-library/code-library/#leverage-devops-automation-code-library","text":"","title":"Leverage DevOps Automation Code Library"},{"location":"how-it-works/code-library/code-library/#overview","text":"A collection of reusable, tested, production-ready E2E infrastructure as code solutions, leveraged by modules written in Terraform, Ansible, Jenkinsfiles, Dockerfiles, Helm charts and Makefiles).","title":"Overview"},{"location":"how-it-works/code-library/code-library/#model","text":"Our development model is strongly based on code reusability","title":"Model"},{"location":"how-it-works/code-library/code-library/#reusability","text":"High level summary of the the code reusability efficiency Considerations Above detailed % are to be seen as estimates AWS PCI-DSS Reference article AWS HIPAA Reference article AWS GDPR Reference article","title":"Reusability"},{"location":"how-it-works/code-library/code-library/#modules","text":"DevOps Automation Code Library development and implementation workflow","title":"Modules"},{"location":"how-it-works/code-library/modules-library-per-tech/","text":"DevOps Code Automation Library Modules \u00b6 Open Source Modules Repos \u00b6 Category URLs Ansible Galaxy Roles bb-leverage-ansible-roles-list Dockerfiles bb-leverage-dockerfiles-list Helm Charts bb-leverage-helm-charts-list Jenkinsfiles Library bb-leverage-jenkinsfiles-lib Terraform Modules bb-leverage-terraform-modules-list Open Source + Private Modules Repos (via GitHub Teams) \u00b6 Repositories Details Reference Architecture Most of the AWS resources are here, divided by account. Dockerfiles These are Terraform module we created/imported to build reusable resources / stacks. Ansible Playbooks & Roles Playbooks we use for provisioning servers such as Jenkins, Spinnaker, Vault, and so on. Jenkins Modules Module we use in our Jenkins pipelines to perform repeated tasks such as posting to Slack, interacting with AWS CLI, etc. CloudFormation Modules Local development via Docker Compose. Helm Charts Complementary Jenkins pipelines to clean docker images, unseal Vault, and more. Also SecOps jobs can be found here. Terraform Modules Jenkins pipelines, docker images, and other resources used for load testing.","title":"Modules per Tech"},{"location":"how-it-works/code-library/modules-library-per-tech/#devops-code-automation-library-modules","text":"","title":"DevOps Code Automation Library Modules"},{"location":"how-it-works/code-library/modules-library-per-tech/#open-source-modules-repos","text":"Category URLs Ansible Galaxy Roles bb-leverage-ansible-roles-list Dockerfiles bb-leverage-dockerfiles-list Helm Charts bb-leverage-helm-charts-list Jenkinsfiles Library bb-leverage-jenkinsfiles-lib Terraform Modules bb-leverage-terraform-modules-list","title":"Open Source Modules Repos"},{"location":"how-it-works/code-library/modules-library-per-tech/#open-source-private-modules-repos-via-github-teams","text":"Repositories Details Reference Architecture Most of the AWS resources are here, divided by account. Dockerfiles These are Terraform module we created/imported to build reusable resources / stacks. Ansible Playbooks & Roles Playbooks we use for provisioning servers such as Jenkins, Spinnaker, Vault, and so on. Jenkins Modules Module we use in our Jenkins pipelines to perform repeated tasks such as posting to Slack, interacting with AWS CLI, etc. CloudFormation Modules Local development via Docker Compose. Helm Charts Complementary Jenkins pipelines to clean docker images, unseal Vault, and more. Also SecOps jobs can be found here. Terraform Modules Jenkins pipelines, docker images, and other resources used for load testing.","title":"Open Source + Private Modules Repos (via GitHub Teams)"},{"location":"how-it-works/compute/k8s-eks/","text":"","title":"K8s EKS"},{"location":"how-it-works/compute/k8s-kops/","text":"","title":"K8s Kops"},{"location":"how-it-works/compute/serverless/","text":"","title":"Serverless"},{"location":"how-it-works/costs/costs/","text":"","title":"Costs"},{"location":"how-it-works/database/database/","text":"","title":"Databases"},{"location":"how-it-works/database/mysql/","text":"","title":"MySQL"},{"location":"how-it-works/database/postgres/","text":"","title":"PostgresSQL"},{"location":"how-it-works/identities/identities/","text":"Identity and Access Management (IAM) Layer \u00b6 Summary \u00b6 Having this official AWS resource as reference we've define a security account structure for managing multiple accounts. User Management Definitions IAM users will strictly be created and centralized in the Security account (member accounts IAM Users could be exceptionally created for very specific tools that still don\u2019t support IAM roles for cross-account auth). All access to resources within the Client organization will be assigned via policy documents attached to IAM roles or groups. All IAM roles and groups will have the least privileges required to properly work. IAM AWS and Customer managed policies will be defined, inline policies will be avoided whenever possible. All user management will be maintained as code and will reside in the DevOps repository. All users will have MFA enabled whenever possible (VPN and AWS Web Console). Root user credentials will be rotated and secured. MFA for root will be enabled. IAM Access Keys for root will be disabled. IAM root access will be monitored via CloudWatch Alerts. Why multi account IAM strategy? Creating a security relationship between accounts makes it even easier for companies to assess the security of AWS-based deployments, centralize security monitoring and management, manage identity and access, and provide audit and compliance monitoring services Figure: AWS Organization Security account structure for managing multiple accounts (just as reference). IAM Groups & Roles definition \u00b6 AWS Org member accounts IAM groups : Account Name AWS Org Member Accounts IAM Groups Admin Auditor DevOps DeployMaster project-root x project-security x x x x AWS Org member accounts IAM roles : Account Name AWS Org Member Accounts IAM Roles Admin Auditor DevOps DeployMaster OrganizationAccountAccessRole project-root x project-security x x x x project-shared x x x x x project-legacy x x x project-apps-devstg x x x x x project-apps-prd x x x x x","title":"Identities"},{"location":"how-it-works/identities/identities/#identity-and-access-management-iam-layer","text":"","title":"Identity and Access Management (IAM) Layer"},{"location":"how-it-works/identities/identities/#summary","text":"Having this official AWS resource as reference we've define a security account structure for managing multiple accounts. User Management Definitions IAM users will strictly be created and centralized in the Security account (member accounts IAM Users could be exceptionally created for very specific tools that still don\u2019t support IAM roles for cross-account auth). All access to resources within the Client organization will be assigned via policy documents attached to IAM roles or groups. All IAM roles and groups will have the least privileges required to properly work. IAM AWS and Customer managed policies will be defined, inline policies will be avoided whenever possible. All user management will be maintained as code and will reside in the DevOps repository. All users will have MFA enabled whenever possible (VPN and AWS Web Console). Root user credentials will be rotated and secured. MFA for root will be enabled. IAM Access Keys for root will be disabled. IAM root access will be monitored via CloudWatch Alerts. Why multi account IAM strategy? Creating a security relationship between accounts makes it even easier for companies to assess the security of AWS-based deployments, centralize security monitoring and management, manage identity and access, and provide audit and compliance monitoring services Figure: AWS Organization Security account structure for managing multiple accounts (just as reference).","title":"Summary"},{"location":"how-it-works/identities/identities/#iam-groups-roles-definition","text":"AWS Org member accounts IAM groups : Account Name AWS Org Member Accounts IAM Groups Admin Auditor DevOps DeployMaster project-root x project-security x x x x AWS Org member accounts IAM roles : Account Name AWS Org Member Accounts IAM Roles Admin Auditor DevOps DeployMaster OrganizationAccountAccessRole project-root x project-security x x x x project-shared x x x x x project-legacy x x x project-apps-devstg x x x x x project-apps-prd x x x x x","title":"IAM Groups &amp; Roles definition"},{"location":"how-it-works/monitoring/logs/","text":"","title":"Logs"},{"location":"how-it-works/monitoring/metrics/","text":"","title":"Metrics"},{"location":"how-it-works/monitoring/monitoring/","text":"","title":"Monitoring"},{"location":"how-it-works/monitoring/tracing/","text":"","title":"Tracing"},{"location":"how-it-works/network/dns/","text":"","title":"DNS"},{"location":"how-it-works/network/vpc-peering/","text":"Diagram: Network Service (cross-account VPC peering ) \u00b6 Figure: AWS multi account Organization VPC Peering topology (just as reference). Figure: AWS multi account Organization VPC Peering routing (just as reference).","title":"VPC Peering"},{"location":"how-it-works/network/vpc-peering/#diagram-network-service-cross-account-vpc-peering","text":"Figure: AWS multi account Organization VPC Peering topology (just as reference). Figure: AWS multi account Organization VPC Peering routing (just as reference).","title":"Diagram: Network Service (cross-account VPC peering)"},{"location":"how-it-works/network/vpc/","text":"Network Layer \u00b6 In this section we detail all the network design related specifications VPCs CIDR blocks VPC Gateways: Internet, NAT, VPN. VPC Peerings VPC DNS Private Hosted Zones Associations. Network ACLS (NACLs) VPCs IP Addressing Plan (CIDR blocks sizing) \u00b6 Introduction VPCs can vary in size from 16 addresses (/28 netmask) to 65,536 addresses (/16 netmask). In order to size a VPC correctly, it is important to understand the number, types, and sizes of workloads expected to run in it, as well as workload elasticity and load balancing requirements. Keep in mind that there is no charge for using Amazon VPC (aside from EC2 charges), therefore cost should not be a factor when determining the appropriate size for your VPC, so make sure you size your VPC for growth. Moving workloads or AWS resources between networks is not a trivial task, so be generous in your IP address estimates to give yourself plenty of room to grow, deploy new workloads, or change your VPC design configuration from one to another. The majority of AWS customers use VPCs with a /16 netmask and subnets with /24 netmasks. The primary reason AWS customers select smaller VPC and subnet sizes is to avoid overlapping network addresses with existing networks. So having AWS single VPC Design we've choosen a Medium/Small VPC/Subnet addressing plan which would probably fit a broad range variety of use cases Networking - IP Addressing \u00b6 Starting CIDR Segment (AWS Org) AWS Org IP Addressing calculation is presented below based on segment 172.16.0.0.0/12 We started from 172.16.0.0.0/12 and subnetted to /20 Resulting in Total Subnets: 256 2 x AWS Account with Hosts/SubNet: 4094 1ry VPC + 2ry VPC 1ry VPC DR + 2ry VPC DR Individual CIDR Segments (VPCs) Then each of these are /20 to /24 Considering the whole Starting CIDR Segment (AWS Org) before declared, we'll start at 172.18.0.0/20 shared 1ry VPC CIDR: 172.18.0.0/24 2ry VPC CIDR: 172.18.16.0/24 1ry VPC DR CIDR: 172.18.32.0/24 2ry VPC DR CIDR: 172.18.48.0/24 apps-devstg 1ry VPC CIDR: 172.18.64.0/24 2ry VPC CIDR: 172.18.80.0/24 1ry VPC DR CIDR: 172.18.96.0/24 2ry VPC DR CIDR: 172.18.112.0/24 apps-prd 1ry VPC CIDR: 172.18.128.0/24 2ry VPC CIDR: 172.18.144.0/24 1ry VPC DR CIDR: 172.18.160.0/24 2ry VPC DR CIDR: 172.18.176.0/24 Resulting in Subnets: 16 x VPC VPC Subnets with Hosts/Net: 256. Eg: apps-devstg account \u2192 us-east-1 w/ 3 AZs \u2192 3 x Private Subnets /az + 3 x Public Subnets /az 1ry VPC CIDR: 172.18.64.0/24 Subnets: Private 172.18.64.0/24, 172.18.66.0/24 and 172.18.68.0/24 Public 172.18.65.0/24, 172.18.67.0/24 and 172.18.69.0/24 Planned VPCs \u00b6 Having defined the initial VPC that will be created in the different accounts that were defined, we are going to create subnets in each of these VPCs defining Private and Public subnets split among different availability zones: Subnet address Netmask Range of addresses Hosts Assignment 172.18.0.0/20 255.255.240.0 172.18.0.0 - 172.18.15.255 4094 1ry VPC: shared 172.18.16.0/20 255.255.240.0 172.18.16.0 - 172.18.31.255 4094 2ry VPC: shared 172.18.32.0/20 255.255.240.0 172.18.32.0 - 172.18.47.255 4094 1ry VPC DR: shared 172.18.48.0/20 255.255.240.0 172.18.48.0 - 172.18.63.255 4094 2ry VPC DR: shared 172.18.64.0/20 255.255.240.0 172.18.64.0 - 172.18.79.255 4094 1ry VPC: apps-devstg 172.18.80.0/20 255.255.240.0 172.18.80.0 - 172.18.95.255 4094 2ry VPC: apps-devstg 172.18.96.0/20 255.255.240.0 172.18.96.0 - 172.18.111.255 4094 1ry VPC DR: apps-devstg 172.18.112.0/20 255.255.240.0 172.18.112.0 - 172.18.127.255 4094 2ry VPC DR: apps-devstg 172.18.128.0/20 255.255.240.0 172.18.128.0 - 172.18.143.255 4094 1ry VPC: apps-prd 172.18.144.0/20 255.255.240.0 172.18.144.0 - 172.18.159.255 4094 2ry VPC: apps-prd 172.18.160.0/20 255.255.240.0 172.18.160.0 - 172.18.175.255 4094 1ry VPC DR: apps-prd 172.18.176.0/20 255.255.240.0 172.18.176.0 - 172.18.191.255 4094 2ry VPC DR: apps-prd Considerations \u00b6 Design considerations AWS EKS: Docker runs in the 172.17.0.0/16 CIDR range in Amazon EKS clusters. We recommend that your cluster's VPC subnets do not overlap this range. Otherwise, you will receive the following error: Error: : error upgrading connection: error dialing backend: dial tcp 172.17.nn.nn:10250: getsockopt: no route to host Read more: AWS EKS network requirements Reserved IP Addresses The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance. For example, in a subnet with CIDR block 10.0.0.0/24, the following five IP addresses are reserved. For more AWS VPC Subnets IP addressing","title":"VPC"},{"location":"how-it-works/network/vpc/#network-layer","text":"In this section we detail all the network design related specifications VPCs CIDR blocks VPC Gateways: Internet, NAT, VPN. VPC Peerings VPC DNS Private Hosted Zones Associations. Network ACLS (NACLs)","title":"Network Layer"},{"location":"how-it-works/network/vpc/#vpcs-ip-addressing-plan-cidr-blocks-sizing","text":"Introduction VPCs can vary in size from 16 addresses (/28 netmask) to 65,536 addresses (/16 netmask). In order to size a VPC correctly, it is important to understand the number, types, and sizes of workloads expected to run in it, as well as workload elasticity and load balancing requirements. Keep in mind that there is no charge for using Amazon VPC (aside from EC2 charges), therefore cost should not be a factor when determining the appropriate size for your VPC, so make sure you size your VPC for growth. Moving workloads or AWS resources between networks is not a trivial task, so be generous in your IP address estimates to give yourself plenty of room to grow, deploy new workloads, or change your VPC design configuration from one to another. The majority of AWS customers use VPCs with a /16 netmask and subnets with /24 netmasks. The primary reason AWS customers select smaller VPC and subnet sizes is to avoid overlapping network addresses with existing networks. So having AWS single VPC Design we've choosen a Medium/Small VPC/Subnet addressing plan which would probably fit a broad range variety of use cases","title":"VPCs IP Addressing Plan (CIDR blocks sizing)"},{"location":"how-it-works/network/vpc/#networking-ip-addressing","text":"Starting CIDR Segment (AWS Org) AWS Org IP Addressing calculation is presented below based on segment 172.16.0.0.0/12 We started from 172.16.0.0.0/12 and subnetted to /20 Resulting in Total Subnets: 256 2 x AWS Account with Hosts/SubNet: 4094 1ry VPC + 2ry VPC 1ry VPC DR + 2ry VPC DR Individual CIDR Segments (VPCs) Then each of these are /20 to /24 Considering the whole Starting CIDR Segment (AWS Org) before declared, we'll start at 172.18.0.0/20 shared 1ry VPC CIDR: 172.18.0.0/24 2ry VPC CIDR: 172.18.16.0/24 1ry VPC DR CIDR: 172.18.32.0/24 2ry VPC DR CIDR: 172.18.48.0/24 apps-devstg 1ry VPC CIDR: 172.18.64.0/24 2ry VPC CIDR: 172.18.80.0/24 1ry VPC DR CIDR: 172.18.96.0/24 2ry VPC DR CIDR: 172.18.112.0/24 apps-prd 1ry VPC CIDR: 172.18.128.0/24 2ry VPC CIDR: 172.18.144.0/24 1ry VPC DR CIDR: 172.18.160.0/24 2ry VPC DR CIDR: 172.18.176.0/24 Resulting in Subnets: 16 x VPC VPC Subnets with Hosts/Net: 256. Eg: apps-devstg account \u2192 us-east-1 w/ 3 AZs \u2192 3 x Private Subnets /az + 3 x Public Subnets /az 1ry VPC CIDR: 172.18.64.0/24 Subnets: Private 172.18.64.0/24, 172.18.66.0/24 and 172.18.68.0/24 Public 172.18.65.0/24, 172.18.67.0/24 and 172.18.69.0/24","title":"Networking - IP Addressing"},{"location":"how-it-works/network/vpc/#planned-vpcs","text":"Having defined the initial VPC that will be created in the different accounts that were defined, we are going to create subnets in each of these VPCs defining Private and Public subnets split among different availability zones: Subnet address Netmask Range of addresses Hosts Assignment 172.18.0.0/20 255.255.240.0 172.18.0.0 - 172.18.15.255 4094 1ry VPC: shared 172.18.16.0/20 255.255.240.0 172.18.16.0 - 172.18.31.255 4094 2ry VPC: shared 172.18.32.0/20 255.255.240.0 172.18.32.0 - 172.18.47.255 4094 1ry VPC DR: shared 172.18.48.0/20 255.255.240.0 172.18.48.0 - 172.18.63.255 4094 2ry VPC DR: shared 172.18.64.0/20 255.255.240.0 172.18.64.0 - 172.18.79.255 4094 1ry VPC: apps-devstg 172.18.80.0/20 255.255.240.0 172.18.80.0 - 172.18.95.255 4094 2ry VPC: apps-devstg 172.18.96.0/20 255.255.240.0 172.18.96.0 - 172.18.111.255 4094 1ry VPC DR: apps-devstg 172.18.112.0/20 255.255.240.0 172.18.112.0 - 172.18.127.255 4094 2ry VPC DR: apps-devstg 172.18.128.0/20 255.255.240.0 172.18.128.0 - 172.18.143.255 4094 1ry VPC: apps-prd 172.18.144.0/20 255.255.240.0 172.18.144.0 - 172.18.159.255 4094 2ry VPC: apps-prd 172.18.160.0/20 255.255.240.0 172.18.160.0 - 172.18.175.255 4094 1ry VPC DR: apps-prd 172.18.176.0/20 255.255.240.0 172.18.176.0 - 172.18.191.255 4094 2ry VPC DR: apps-prd","title":"Planned VPCs"},{"location":"how-it-works/network/vpc/#considerations","text":"Design considerations AWS EKS: Docker runs in the 172.17.0.0/16 CIDR range in Amazon EKS clusters. We recommend that your cluster's VPC subnets do not overlap this range. Otherwise, you will receive the following error: Error: : error upgrading connection: error dialing backend: dial tcp 172.17.nn.nn:10250: getsockopt: no route to host Read more: AWS EKS network requirements Reserved IP Addresses The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance. For example, in a subnet with CIDR block 10.0.0.0/24, the following five IP addresses are reserved. For more AWS VPC Subnets IP addressing","title":"Considerations"},{"location":"how-it-works/organization/organization/","text":"Reference Architecture: Terraform AWS Organizations Account Baseline \u00b6 Overview \u00b6 This repository contains all Terraform configuration files used to create Binbash Leverage Reference AWS Organizations Multi-Account baseline layout. Why AWS Organizations? This approach allows it to have a hierarchical structure of AWS accounts, providing additional security isolation and the ability to separate resources into Organizational Units with it associated Service Control Policies (SCP). Considering that a current AWS account/s was/were already active (Client AWS Legacy Account), this one will then be invited to be a \u201cmember account\u201d of the AWS Organization architecture. In the future, once all Client\u2019s Legacy dev, stage, prod and other resources for the Project applications are running in the new accounts architecture, meaning a full AWS Organizations approach, all the already migrated assets from the \u2018Legacy\u2019 account should be decommissioned. This account will remain with the necessary services, such as DNS, among others. AWS Organization Accounts Layout \u00b6 The following block provides a brief explanation of the chosen AWS Organization Accounts layout: + devstg/ (resources for dev apps/services account) ... + prod/ (resources for prod apps/services account) ... + root/ (resources for the root-org account) ... + security/ (resources for the security + users account) ... + shared/ (resources for the shared account) ... + legacy/ (resources for the legacy/pre-existing account) ... NOTE: Image just as reference AWS Organization Accounts description \u00b6 Our default AWS Organizations terraform layout solution includes 5 accounts + 1 or N Accts (if you invite pre-existing AWS Account/s). Account Description Root Organizations Used to manage configuration and access to AWS Org managed accounts. The AWS Organizations account provides the ability to create and financially manage member accounts, it contains AWS Organizations Service Control Policies(SCPs). Shared Services / Resources Reference for creating infrastructure shared services such as directory services, DNS, VPN Solution, Monitoring tools like Prometheus and Graphana, CI/CD server (Jenkins, Drone, Spinnaker, etc), centralized logging solution like ELK and Vault Server (Hashicorp Vault) Security Intended for centralized user mamangement via IAM roles based cross-org auth approach (IAM roles per account to be assumed still needed. Also to centralize AWS CloudTrail and AWS Config logs, and used as the master AWS GuardDuty Account Legacy Your pre existing AWS Accounts to be invited as members of the new AWS Organization, probably several services and workloads are going to be progressively migrated to your new Accounts. Apps DevStg Host your DEV, QA and STG environment workloads Compute / Web App Servers (K8s Clusters and Lambda Functions), Load Balancers, DB Servers, Caching Services, Job queues & Servers, Data, Storage, CDN Apps Prod Host your PROD environment workloads Compute / Web App Servers (K8s Clusters and Lambda Functions), Load Balancers, DB Servers, Caching Services, Job queues & Servers, Data, Storage, CDN Benefits of AWS Organizations Billing: Consolidated billing for all your accounts within organization, enhanced per account cost filtering and RI usage Security I: Extra security layer: You get fully isolated infrastructure for different organizations units in your projects, eg: Dev, Prod, Shared Resources, Security, Users, BI, etc. Security II: Using AWS Organization you may use Service Control Policies (SCPs) to control which AWS services are available within different accounts. Networking: Connectivity and access will be securely setup via VPC peering + NACLS + Sec Groups everything with private endpoints only accessible v\u00eda Pritunl VPN significantly reducing the surface of attack. User Mgmt: You can manage all your IAM resources (users/groups/roles) and policies in one place (usually, security/users account) and use AssumeRole to works with org accounts. Operations: Will reduce the blast radius to the maximum possible. Compatibility: Legacy accounts can (probably should) be invited as a member of the new Organization and afterwards even imported into your terraform code . Migration: After having your baseline AWS Org reference cloud solutions architecture deployed (IAM, VPC, NACLS, VPC-Peering, DNS Cross-Org, CloudTrail, etc.) you're ready to start progressively orchestrating new resources in order to segregate different Environment and Services per account. This approach will allow you to start a 1 by 1 Blue/Green (Red/Black) migration without affecting any of your services at all . You would like to take advantage of an Active-Active DNS switchover approach (nice as DR exercise too). EXAMPLE: Jenkins CI Server Migration steps: Let's say you have your EC2_A ( jenkins.aws.domain.com ) in Account_A (Legacy), so you could deploy a brand new EC2_B Jenkins Instance in Account_B (Shared Resources). Temporally associated with jenkins2.aws.domain.com Sync it's current data ( /var/lib/jenkins ) Test and fully validate every job and pipeline works as expected. In case you haven't finished your validations we highly recommend to declare everything as code and fully automated so as to destroy and re-create your under development env on demand to save costs. Finally switch jenkins2.aws.domain.com -> to -> jenkins.aws.domain.com Stop your old EC2_A. If everything looks fine after after 2/4 weeks you could terminate your EC2_A (hope everything is as code and just terraform destroy ) Considering the previously detailed steps plan your roadmap to move forward with every other component to be migrated. Read more \u00b6 AWS reference links Consider the following AWS official links as reference: AWS Multiple Account User Management Strategy AWS Muttiple Account Security Strategy AWS Multiple Account Billing Strategy AWS Secure Account Setup Authentication and Access Control for AWS Organizations (keep in mind EC2 and other services can also use AWS IAM Roles to get secure cross-account access)","title":"AWS Organization"},{"location":"how-it-works/organization/organization/#reference-architecture-terraform-aws-organizations-account-baseline","text":"","title":"Reference Architecture: Terraform AWS Organizations Account Baseline"},{"location":"how-it-works/organization/organization/#overview","text":"This repository contains all Terraform configuration files used to create Binbash Leverage Reference AWS Organizations Multi-Account baseline layout. Why AWS Organizations? This approach allows it to have a hierarchical structure of AWS accounts, providing additional security isolation and the ability to separate resources into Organizational Units with it associated Service Control Policies (SCP). Considering that a current AWS account/s was/were already active (Client AWS Legacy Account), this one will then be invited to be a \u201cmember account\u201d of the AWS Organization architecture. In the future, once all Client\u2019s Legacy dev, stage, prod and other resources for the Project applications are running in the new accounts architecture, meaning a full AWS Organizations approach, all the already migrated assets from the \u2018Legacy\u2019 account should be decommissioned. This account will remain with the necessary services, such as DNS, among others.","title":"Overview"},{"location":"how-it-works/organization/organization/#aws-organization-accounts-layout","text":"The following block provides a brief explanation of the chosen AWS Organization Accounts layout: + devstg/ (resources for dev apps/services account) ... + prod/ (resources for prod apps/services account) ... + root/ (resources for the root-org account) ... + security/ (resources for the security + users account) ... + shared/ (resources for the shared account) ... + legacy/ (resources for the legacy/pre-existing account) ... NOTE: Image just as reference","title":"AWS Organization Accounts Layout"},{"location":"how-it-works/organization/organization/#aws-organization-accounts-description","text":"Our default AWS Organizations terraform layout solution includes 5 accounts + 1 or N Accts (if you invite pre-existing AWS Account/s). Account Description Root Organizations Used to manage configuration and access to AWS Org managed accounts. The AWS Organizations account provides the ability to create and financially manage member accounts, it contains AWS Organizations Service Control Policies(SCPs). Shared Services / Resources Reference for creating infrastructure shared services such as directory services, DNS, VPN Solution, Monitoring tools like Prometheus and Graphana, CI/CD server (Jenkins, Drone, Spinnaker, etc), centralized logging solution like ELK and Vault Server (Hashicorp Vault) Security Intended for centralized user mamangement via IAM roles based cross-org auth approach (IAM roles per account to be assumed still needed. Also to centralize AWS CloudTrail and AWS Config logs, and used as the master AWS GuardDuty Account Legacy Your pre existing AWS Accounts to be invited as members of the new AWS Organization, probably several services and workloads are going to be progressively migrated to your new Accounts. Apps DevStg Host your DEV, QA and STG environment workloads Compute / Web App Servers (K8s Clusters and Lambda Functions), Load Balancers, DB Servers, Caching Services, Job queues & Servers, Data, Storage, CDN Apps Prod Host your PROD environment workloads Compute / Web App Servers (K8s Clusters and Lambda Functions), Load Balancers, DB Servers, Caching Services, Job queues & Servers, Data, Storage, CDN Benefits of AWS Organizations Billing: Consolidated billing for all your accounts within organization, enhanced per account cost filtering and RI usage Security I: Extra security layer: You get fully isolated infrastructure for different organizations units in your projects, eg: Dev, Prod, Shared Resources, Security, Users, BI, etc. Security II: Using AWS Organization you may use Service Control Policies (SCPs) to control which AWS services are available within different accounts. Networking: Connectivity and access will be securely setup via VPC peering + NACLS + Sec Groups everything with private endpoints only accessible v\u00eda Pritunl VPN significantly reducing the surface of attack. User Mgmt: You can manage all your IAM resources (users/groups/roles) and policies in one place (usually, security/users account) and use AssumeRole to works with org accounts. Operations: Will reduce the blast radius to the maximum possible. Compatibility: Legacy accounts can (probably should) be invited as a member of the new Organization and afterwards even imported into your terraform code . Migration: After having your baseline AWS Org reference cloud solutions architecture deployed (IAM, VPC, NACLS, VPC-Peering, DNS Cross-Org, CloudTrail, etc.) you're ready to start progressively orchestrating new resources in order to segregate different Environment and Services per account. This approach will allow you to start a 1 by 1 Blue/Green (Red/Black) migration without affecting any of your services at all . You would like to take advantage of an Active-Active DNS switchover approach (nice as DR exercise too). EXAMPLE: Jenkins CI Server Migration steps: Let's say you have your EC2_A ( jenkins.aws.domain.com ) in Account_A (Legacy), so you could deploy a brand new EC2_B Jenkins Instance in Account_B (Shared Resources). Temporally associated with jenkins2.aws.domain.com Sync it's current data ( /var/lib/jenkins ) Test and fully validate every job and pipeline works as expected. In case you haven't finished your validations we highly recommend to declare everything as code and fully automated so as to destroy and re-create your under development env on demand to save costs. Finally switch jenkins2.aws.domain.com -> to -> jenkins.aws.domain.com Stop your old EC2_A. If everything looks fine after after 2/4 weeks you could terminate your EC2_A (hope everything is as code and just terraform destroy ) Considering the previously detailed steps plan your roadmap to move forward with every other component to be migrated.","title":"AWS Organization Accounts description"},{"location":"how-it-works/organization/organization/#read-more","text":"AWS reference links Consider the following AWS official links as reference: AWS Multiple Account User Management Strategy AWS Muttiple Account Security Strategy AWS Multiple Account Billing Strategy AWS Secure Account Setup Authentication and Access Control for AWS Organizations (keep in mind EC2 and other services can also use AWS IAM Roles to get secure cross-account access)","title":"Read more"},{"location":"how-it-works/reliability/backups/","text":"","title":"Backups"},{"location":"how-it-works/reliability/dr/","text":"","title":"Disaster Recovery"},{"location":"how-it-works/secrets/secrets/","text":"","title":"Secrets"},{"location":"how-it-works/security/services/","text":"AWS Security & Compliance Services \u00b6 Security Directives There will not be any instance port or service port open to general access, unless justified by business reasons, and we\u2019ll take alternative means of security to mitigate any possible risk. Every account will have a set of active services that will allow for administrative users (SecOps) to audit all actions and track potentially dangerous behavior. All services will be enabled via IaC (Terraform or SDK and tracked in the proper git repo). AWS Managed Security Services AWS IAM Access Analyzer: Generates comprehensive findings that identify resources policies for public or cross-account accessibility, monitors and helps you refine permissions. Provides the highest levels of security assurance. AWS Config: Tracks changes made to AWS resources over time, making possible to return to a previous state. Monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired compliance rule set. Adds accountability factor. AWS Cloudtrail: Stores logs over all calls made to AWS APIs, coming from web console, command line or any other. Allowing us to monitor it via CW Dashboards and notifications. AWS VPC Flow Logs: Enables us to examine individual Network Interfaces logs, to address network issues and also monitor suspicious behavior. AWS Web Application Firewall: Optional but if not used, it is recommended that a similar service is used, such as Cloudflare. When paired to an Application Load Balancer or Cloudfront distribution, it checks incoming requests to detect and block OWAPS Top10 attacks, such as SQL injection, XSS and others. AWS Inspector: Is an automated security assessment service that helps improve the security and compliance of infrastructure and applications deployed on AWS. AWS Guard Duty: Is a managed threat detection service that continuously monitors for malicious or unauthorized behavior to help you protect your AWS accounts and workloads. Detects unusual API calls or potentially unauthorized deployments (possible account compromise) and potentially compromised instances or reconnaissance by attackers. AWS Security Logs Other access logs from client-facing resources will be stored in the Security account.","title":"Services"},{"location":"how-it-works/security/services/#aws-security-compliance-services","text":"Security Directives There will not be any instance port or service port open to general access, unless justified by business reasons, and we\u2019ll take alternative means of security to mitigate any possible risk. Every account will have a set of active services that will allow for administrative users (SecOps) to audit all actions and track potentially dangerous behavior. All services will be enabled via IaC (Terraform or SDK and tracked in the proper git repo). AWS Managed Security Services AWS IAM Access Analyzer: Generates comprehensive findings that identify resources policies for public or cross-account accessibility, monitors and helps you refine permissions. Provides the highest levels of security assurance. AWS Config: Tracks changes made to AWS resources over time, making possible to return to a previous state. Monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired compliance rule set. Adds accountability factor. AWS Cloudtrail: Stores logs over all calls made to AWS APIs, coming from web console, command line or any other. Allowing us to monitor it via CW Dashboards and notifications. AWS VPC Flow Logs: Enables us to examine individual Network Interfaces logs, to address network issues and also monitor suspicious behavior. AWS Web Application Firewall: Optional but if not used, it is recommended that a similar service is used, such as Cloudflare. When paired to an Application Load Balancer or Cloudfront distribution, it checks incoming requests to detect and block OWAPS Top10 attacks, such as SQL injection, XSS and others. AWS Inspector: Is an automated security assessment service that helps improve the security and compliance of infrastructure and applications deployed on AWS. AWS Guard Duty: Is a managed threat detection service that continuously monitors for malicious or unauthorized behavior to help you protect your AWS accounts and workloads. Detects unusual API calls or potentially unauthorized deployments (possible account compromise) and potentially compromised instances or reconnaissance by attackers. AWS Security Logs Other access logs from client-facing resources will be stored in the Security account.","title":"AWS Security &amp; Compliance Services"},{"location":"how-it-works/security/vpn/","text":"VPN Server \u00b6 To securely and scalable privately access AWS Cross Organization resources we\u2019ll implement Pritunl VPN Server \u00b6 Security Directives Private HTTP endpoints for Applications (FrontEnd + APIs), SSH, monitoring & logging (UI / Dashboards) among others. Eg: Jenkins, DroneCI, EFK, Prometheus, Spinnaker, Grafana. K8s API via kubectl private endpoint eg: avoiding emergency K8s API vulnerability patching. Limit exposure: Limit the exposure of the workload to the internet and internal networks by only allowing minimum required access -> Avoiding exposure for Dev/QA/Stg http endpoints The Pritunl OpenVPN Linux instance is hardened and only runs this VPN solution. All other ports/access is restricted. Each VPN user can be required to use MFA to connect via VPN (as well as strong passwords). This combination makes almost impossible for an outsider to gain access via VPN. Centralized access and audit logs. Read More \u00b6 Pritunl - Open Source Enterprise Distributed OpenVPN, IPsec and WireGuard Server Specifications","title":"VPN"},{"location":"how-it-works/security/vpn/#vpn-server","text":"","title":"VPN Server"},{"location":"how-it-works/security/vpn/#to-securely-and-scalable-privately-access-aws-cross-organization-resources-well-implement-pritunl-vpn-server","text":"Security Directives Private HTTP endpoints for Applications (FrontEnd + APIs), SSH, monitoring & logging (UI / Dashboards) among others. Eg: Jenkins, DroneCI, EFK, Prometheus, Spinnaker, Grafana. K8s API via kubectl private endpoint eg: avoiding emergency K8s API vulnerability patching. Limit exposure: Limit the exposure of the workload to the internet and internal networks by only allowing minimum required access -> Avoiding exposure for Dev/QA/Stg http endpoints The Pritunl OpenVPN Linux instance is hardened and only runs this VPN solution. All other ports/access is restricted. Each VPN user can be required to use MFA to connect via VPN (as well as strong passwords). This combination makes almost impossible for an outsider to gain access via VPN. Centralized access and audit logs.","title":"To securely and scalable privately access AWS Cross Organization resources we\u2019ll implement Pritunl VPN Server"},{"location":"how-it-works/security/vpn/#read-more","text":"Pritunl - Open Source Enterprise Distributed OpenVPN, IPsec and WireGuard Server Specifications","title":"Read More"},{"location":"how-it-works/storage/storage/","text":"","title":"Storage"},{"location":"how-it-works/tools/tools/","text":"","title":"Tools"},{"location":"user-guide/","text":"Workflow \u00b6 Terraform Workflow \u00b6 Make sure you've read the 'Pre-requisites' section 1st steps Get into the folder that you need to work with (e.g. 2_identities ) Run make init Make whatever changes you need to make Run make plan if you only mean to preview those changes Run make apply if you want to review and likely apply those changes NOTE: If desired at step #5 you could submit a PR, allowing you and the rest of the team to understand and review what changes would be made to your AWS Cloud Architecture components before executing make apply ( terraform apply ). This brings the huge benefit of treating changes with a GitOps oriented approach, basically as we should treat any other code & infrastructure change, and integrate it with the rest of our tools and practices like CI/CD, in","title":"Basic usage"},{"location":"user-guide/#workflow","text":"","title":"Workflow"},{"location":"user-guide/#terraform-workflow","text":"Make sure you've read the 'Pre-requisites' section 1st steps Get into the folder that you need to work with (e.g. 2_identities ) Run make init Make whatever changes you need to make Run make plan if you only mean to preview those changes Run make apply if you want to review and likely apply those changes NOTE: If desired at step #5 you could submit a PR, allowing you and the rest of the team to understand and review what changes would be made to your AWS Cloud Architecture components before executing make apply ( terraform apply ). This brings the huge benefit of treating changes with a GitOps oriented approach, basically as we should treat any other code & infrastructure change, and integrate it with the rest of our tools and practices like CI/CD, in","title":"Terraform Workflow"},{"location":"user-guide/configuration/configs/","text":"Files/Folders Organization \u00b6 The following block provides a brief explanation of the chosen files/folders layout: + apps-devstg/ (resources for Apps dev & stg account) ... + apps-prd/ (resources for Apps Prod account) ... + root-org/ (resources for the root-org account) ... + security/ (resources for the security + users account) ... + shared/ (resources for the shared account) ... Configuration files are organized by environments (e.g. dev, stg) and service type (identities, sec, network, etc) to keep any changes made to them separate. Within each of those folders you should find the Terraform files that are used to define all the resources that belong to such environment. figure 1: AWS Organization Architecture Diagram (just as reference). Under every account folder you will see a service layer structure similar to the following: . \u251c\u2500\u2500 apps-devstg \u2502 \u251c\u2500\u2500 10_databases_mysql -- \u2502 \u251c\u2500\u2500 10_databases_pgsql -- \u2502 \u251c\u2500\u2500 1_tf-backend \u2502 \u251c\u2500\u2500 2_identities \u2502 \u251c\u2500\u2500 3_network \u2502 \u251c\u2500\u2500 4_security \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 5_dns \u2502 \u251c\u2500\u2500 6_notifications \u2502 \u251c\u2500\u2500 7_cloud-nuke \u2502 \u251c\u2500\u2500 8_k8s_eks -- \u2502 \u251c\u2500\u2500 8_k8s_kops -- \u2502 \u251c\u2500\u2500 9_backups -- \u2502 \u251c\u2500\u2500 9_storage -- \u2502 \u2514\u2500\u2500 config \u251c\u2500\u2500 apps-prd \u2502 \u251c\u2500\u2500 1_tf-backend -- \u2502 \u251c\u2500\u2500 2_identities -- \u2502 \u251c\u2500\u2500 3_network -- \u2502 \u251c\u2500\u2500 4_security -- \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 5_dns -- \u2502 \u251c\u2500\u2500 6_notifications -- \u2502 \u251c\u2500\u2500 9_backups -- \u2502 \u2514\u2500\u2500 config \u251c\u2500\u2500 root-org \u2502 \u251c\u2500\u2500 1_tf-backend \u2502 \u251c\u2500\u2500 2_identities \u2502 \u251c\u2500\u2500 3_organizations \u2502 \u251c\u2500\u2500 4_security \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 5_cost-mgmt \u2502 \u251c\u2500\u2500 6_notifications \u2502 \u2514\u2500\u2500 config \u251c\u2500\u2500 security \u2502 \u251c\u2500\u2500 1_tf-backend \u2502 \u251c\u2500\u2500 2_identities \u2502 \u251c\u2500\u2500 4_security \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 6_notifications \u2502 \u2514\u2500\u2500 config \u2514\u2500\u2500 shared \u251c\u2500\u2500 1_tf-backend \u251c\u2500\u2500 2_identities \u251c\u2500\u2500 3_network \u251c\u2500\u2500 4_security \u251c\u2500\u2500 4_security_compliance -- \u251c\u2500\u2500 5_dns \u251c\u2500\u2500 6_notifications \u251c\u2500\u2500 7_vpn-server \u251c\u2500\u2500 8_container_registry \u2514\u2500\u2500 config NOTE: As a convention folders with the -- suffix reflect that the resources are not currently created in AWS, basically they've been destroyed or not yet exist. Such separation is meant to avoid situations in which a single folder contains a lot of resources. That is important to avoid because at some point, running terraform plan or apply stats taking too long and that becomes a problem. This organization also provides a layout that is easier to navigate and discover. You simply start with the accounts at the top level and then you get to explore the resource categories within each account. Pre-requisites \u00b6 Makefile \u00b6 We rely on Makefiles as a wrapper to run terraform commands that consistently use the same config files. You are encouraged to inspect those Makefiles to understand what's going on. Terraform \u00b6 Install terraform >= v0.12.20 Run terraform version to check NOTE: Most Makefiles already grant the recs via Dockerized cmds (https://hub.docker.com/repository/docker/binbash/terraform-resources) Remote State \u00b6 In the tf-backend folder you should find all setup scripts or configuration files that need to be run before you can get to work with anything else. IMPORTANT: THIS IS ONLY NEEDED IF THE BACKEND WAS NOT CREATED YET. IF THE BACKEND ALREADY EXISTS YOU JUST USE IT. Configuration \u00b6 Config files can be found in under each 'config' folder. File backend.config contains TF variables that are mainly used to configure TF backend but since profile and region are defined there, we also use them to inject those values into other TF commands. File base.config contains TF variables that we inject to TF commands such as plan or apply and which cannot be stored in backend.config due to TF restrictions. File extra.config similar to base.config but variables declared here are not used by all sub-directories. AWS Profile \u00b6 File backend.config will inject the profile name that TF will use to make changes on AWS. Such profile is usually one that relies on another profile to assume a role to get access to each corresponding account. File @doc/binbash-aws-org-config will be considered to be appended to your .aws/config file note that .aws/config will depend on the IAM profiles declared at your .aws/credentials Read the following page to understand how to set up a profile to assume a role => https://docs.aws.amazon.com/cli/latest/userguide/cli-roles.html","title":"Configs"},{"location":"user-guide/configuration/configs/#filesfolders-organization","text":"The following block provides a brief explanation of the chosen files/folders layout: + apps-devstg/ (resources for Apps dev & stg account) ... + apps-prd/ (resources for Apps Prod account) ... + root-org/ (resources for the root-org account) ... + security/ (resources for the security + users account) ... + shared/ (resources for the shared account) ... Configuration files are organized by environments (e.g. dev, stg) and service type (identities, sec, network, etc) to keep any changes made to them separate. Within each of those folders you should find the Terraform files that are used to define all the resources that belong to such environment. figure 1: AWS Organization Architecture Diagram (just as reference). Under every account folder you will see a service layer structure similar to the following: . \u251c\u2500\u2500 apps-devstg \u2502 \u251c\u2500\u2500 10_databases_mysql -- \u2502 \u251c\u2500\u2500 10_databases_pgsql -- \u2502 \u251c\u2500\u2500 1_tf-backend \u2502 \u251c\u2500\u2500 2_identities \u2502 \u251c\u2500\u2500 3_network \u2502 \u251c\u2500\u2500 4_security \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 5_dns \u2502 \u251c\u2500\u2500 6_notifications \u2502 \u251c\u2500\u2500 7_cloud-nuke \u2502 \u251c\u2500\u2500 8_k8s_eks -- \u2502 \u251c\u2500\u2500 8_k8s_kops -- \u2502 \u251c\u2500\u2500 9_backups -- \u2502 \u251c\u2500\u2500 9_storage -- \u2502 \u2514\u2500\u2500 config \u251c\u2500\u2500 apps-prd \u2502 \u251c\u2500\u2500 1_tf-backend -- \u2502 \u251c\u2500\u2500 2_identities -- \u2502 \u251c\u2500\u2500 3_network -- \u2502 \u251c\u2500\u2500 4_security -- \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 5_dns -- \u2502 \u251c\u2500\u2500 6_notifications -- \u2502 \u251c\u2500\u2500 9_backups -- \u2502 \u2514\u2500\u2500 config \u251c\u2500\u2500 root-org \u2502 \u251c\u2500\u2500 1_tf-backend \u2502 \u251c\u2500\u2500 2_identities \u2502 \u251c\u2500\u2500 3_organizations \u2502 \u251c\u2500\u2500 4_security \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 5_cost-mgmt \u2502 \u251c\u2500\u2500 6_notifications \u2502 \u2514\u2500\u2500 config \u251c\u2500\u2500 security \u2502 \u251c\u2500\u2500 1_tf-backend \u2502 \u251c\u2500\u2500 2_identities \u2502 \u251c\u2500\u2500 4_security \u2502 \u251c\u2500\u2500 4_security_compliance -- \u2502 \u251c\u2500\u2500 6_notifications \u2502 \u2514\u2500\u2500 config \u2514\u2500\u2500 shared \u251c\u2500\u2500 1_tf-backend \u251c\u2500\u2500 2_identities \u251c\u2500\u2500 3_network \u251c\u2500\u2500 4_security \u251c\u2500\u2500 4_security_compliance -- \u251c\u2500\u2500 5_dns \u251c\u2500\u2500 6_notifications \u251c\u2500\u2500 7_vpn-server \u251c\u2500\u2500 8_container_registry \u2514\u2500\u2500 config NOTE: As a convention folders with the -- suffix reflect that the resources are not currently created in AWS, basically they've been destroyed or not yet exist. Such separation is meant to avoid situations in which a single folder contains a lot of resources. That is important to avoid because at some point, running terraform plan or apply stats taking too long and that becomes a problem. This organization also provides a layout that is easier to navigate and discover. You simply start with the accounts at the top level and then you get to explore the resource categories within each account.","title":"Files/Folders Organization"},{"location":"user-guide/configuration/configs/#pre-requisites","text":"","title":"Pre-requisites"},{"location":"user-guide/configuration/configs/#makefile","text":"We rely on Makefiles as a wrapper to run terraform commands that consistently use the same config files. You are encouraged to inspect those Makefiles to understand what's going on.","title":"Makefile"},{"location":"user-guide/configuration/configs/#terraform","text":"Install terraform >= v0.12.20 Run terraform version to check NOTE: Most Makefiles already grant the recs via Dockerized cmds (https://hub.docker.com/repository/docker/binbash/terraform-resources)","title":"Terraform"},{"location":"user-guide/configuration/configs/#remote-state","text":"In the tf-backend folder you should find all setup scripts or configuration files that need to be run before you can get to work with anything else. IMPORTANT: THIS IS ONLY NEEDED IF THE BACKEND WAS NOT CREATED YET. IF THE BACKEND ALREADY EXISTS YOU JUST USE IT.","title":"Remote State"},{"location":"user-guide/configuration/configs/#configuration","text":"Config files can be found in under each 'config' folder. File backend.config contains TF variables that are mainly used to configure TF backend but since profile and region are defined there, we also use them to inject those values into other TF commands. File base.config contains TF variables that we inject to TF commands such as plan or apply and which cannot be stored in backend.config due to TF restrictions. File extra.config similar to base.config but variables declared here are not used by all sub-directories.","title":"Configuration"},{"location":"user-guide/configuration/configs/#aws-profile","text":"File backend.config will inject the profile name that TF will use to make changes on AWS. Such profile is usually one that relies on another profile to assume a role to get access to each corresponding account. File @doc/binbash-aws-org-config will be considered to be appended to your .aws/config file note that .aws/config will depend on the IAM profiles declared at your .aws/credentials Read the following page to understand how to set up a profile to assume a role => https://docs.aws.amazon.com/cli/latest/userguide/cli-roles.html","title":"AWS Profile"}]}